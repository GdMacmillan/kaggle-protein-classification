apiVersion: "kubeflow.org/v1alpha2"
kind: "PyTorchJob"
metadata:
  name: "pytorch-human-protein-atlas"
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      template:
        spec:
          containers:
            - name: pytorch
              image: gcr.io/optfit-kaggle/human-protein-atlas:latest
              env:
              - name: BRANCH
                value: "gordon" # set to your branch
              - name: CLOUD_STORAGE_BUCKET
                value: "hpa-experiments" # where the test results will be uploaded
              - name: TRAIN_SCRIPT
                value: "train_script.sh" # which train script to use
              - name: GOOGLE_APPLICATION_CREDENTIALS_JSON_FILE
                value: /var/secrets/google/gcs-service-account.json
              resources:
                limits:
                  nvidia.com/gpu: 1
              volumeMounts:
                - name: test-volume
                  mountPath: /hpakf-image-data
                - name: google-cloud-key
                  mountPath: /var/secrets/google
          volumes:
            - name: test-volume
              # This GCE PD must already exist.
              gcePersistentDisk:
                pdName: hpakf-data2
                fsType: ext4
                readOnly: true
            - name: google-cloud-key
              secret:
                secretName: gcs-service-account
